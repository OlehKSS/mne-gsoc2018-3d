{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ipysurfer Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Basic Visualization\n",
    "\n",
    "Initialize a basic visualization session and plot a brain mesh. For this purpose we need to provide subject information, e.g. `subject_id`, `subjects_dir`; which type of freesurfer surface mesh we would like to plot, e.g. 'pialed' or 'inflated'; and which hemisphere to plot or whether to plot both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Pial Surface, Both Hemispheres on a Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import os.path as path\n",
    "\n",
    "import mne\n",
    "from ipysurfer import Brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f895931c28be4cccb9e5ef8654131e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p style=\"color: None\"><b>Sample</b></p>'), HBox(children=(Figure(animation=0.0, ca…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = mne.datasets.sample.data_path()\n",
    "\n",
    "subject_id = 'sample'\n",
    "subjects_dir = path.join(data_path, 'subjects')\n",
    "\n",
    "# show both hemispheres on a plot\n",
    "hemi = 'both'\n",
    "surf = 'pial'\n",
    "\n",
    "# Call the Brain object constructor with\n",
    "# parameters to initialize the visualization session.\n",
    "brain = Brain(subject_id, hemi, surf,\n",
    "              size=300, subjects_dir=subjects_dir)\n",
    "brain.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Inflated Surface, Separated Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33889b05a0704397a018417787624376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p style=\"color: None\"><b>Sample</b></p>'), HBox(children=(Figure(animation=0.0, ca…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "surf = 'inflated'\n",
    "# show both hemispheres on separate plots\n",
    "hemi = 'split'\n",
    "\n",
    "# Call the Brain object constructor with\n",
    "# parameters to initialize the visualization session.\n",
    "brain = Brain(subject_id, hemi, surf,\n",
    "              size=300, subjects_dir=subjects_dir)\n",
    "brain.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Activation Data Visualization\n",
    "\n",
    "In this example it is shown how to add activation data to a plot. By default, color bar and input boxes for fmin, fmid and fmax control parameters of a color map are attached to the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In this example it is shown how to add activation data to a plot. By default, color bar and input boxes for `fmin`, `fmid` and `fmax` control parameters of a color map are attached to the plot.\n",
    "\n",
    "A colormap may be sequential or divergent, the latter has defined `center` parameter. The meanings of fmin, fmid and fmax are different for sequential and divergent colormaps. A sequential colormap is characterised by \n",
    "```\n",
    "[fmin, fmid, fmax]\n",
    "```\n",
    "where `fmin` and `fmax` define the edges of the colormap and `fmid` will be the value mapped to the center of the originally chosen colormap. A divergent colormap is characterised by\n",
    "```\n",
    "[center-fmax, center-fmid, center-fmin, center, center+fmin, center+fmid, center+fmax]\n",
    "```\n",
    "i.e., values between center-fmin and center+fmin will not be shown while `center-fmid` will map to the middle of the first half of the original colormap and `center-fmid` to the middle of the second half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "act_data = path.join(data_path, 'MEG/sample/sample_audvis-meg-eeg')\n",
    "\n",
    "# read mne provided example of data\n",
    "stc = mne.read_source_estimate(act_data)\n",
    "\n",
    "# select which hemisphere to plot\n",
    "hemi = 'lh'\n",
    "# select data that corresponds to the 'lh' hemisphere for the selected time moment\n",
    "hemi_data = stc.data[:len(stc.vertices[0]), 10]\n",
    "hemi_vertices = stc.vertices[0]\n",
    "\n",
    "fmin = stc.data.min()\n",
    "fmax = stc.data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cafb87a07de94f01ae5a18460522a6f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p style=\"color: None\"><b>Sample</b></p>'), HBox(children=(Figure(animation=0.0, ca…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "brain_data = Brain(subject_id, hemi, surf,\n",
    "                   size=300, subjects_dir=subjects_dir)\n",
    "\n",
    "brain_data.add_data(hemi_data, fmin=fmin, hemi=hemi,\n",
    "                    fmax=fmax, colormap='hot',\n",
    "                    vertices=hemi_vertices)\n",
    "brain_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Color bar controls can be disabled as in the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c4849e1cef447e9eb130d72457e876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p style=\"color: None\"><b>Sample</b></p>'), HBox(children=(Figure(animation=0.0, ca…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "brain_data = Brain(subject_id, hemi, surf,\n",
    "                   size=300, subjects_dir=subjects_dir)\n",
    "\n",
    "# color bar controls are attached by default, so we need to change parameter value\n",
    "brain_data.add_data(hemi_data, fmin=fmin, hemi=hemi,\n",
    "                    fmax=fmax, colormap='hot',\n",
    "                    vertices=hemi_vertices, colorbar=False)\n",
    "brain_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Activation Data Visualization for Different Time Moments\n",
    "\n",
    "Use `TimeViewer` class to append time viewer widget to the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from ipysurfer import TimeViewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "act_data = path.join(data_path,\n",
    "                     'MEG/sample/sample_audvis-meg-eeg')\n",
    "\n",
    "# read mne provided example of data\n",
    "stc = mne.read_source_estimate(act_data)\n",
    "\n",
    "# select which hemisphere to plot\n",
    "hemi = 'rh'\n",
    "\n",
    "# select data that corresponds to 'lh' hemisphere for each moment of time\n",
    "hemi_data = stc.data[:len(stc.vertices[0]), :]\n",
    "hemi_vertices = stc.vertices[0]\n",
    "\n",
    "# we will need to provide list of time points and select initial time\n",
    "hemi_times = stc.times\n",
    "hemi_initial_time = 0.09\n",
    "\n",
    "# time label formating string to be shown\n",
    "hemi_time_label = 'time=%0.2f ms'\n",
    "\n",
    "fmin = 5\n",
    "fmid = 7\n",
    "fmax = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "900fe6d803084ef88e8d2bc695579aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p style=\"color: None\"><b>Sample</b></p>'), HBox(children=(Figure(animation=500.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "brain_data = Brain(subject_id, hemi, surf,\n",
    "                   size=400, subjects_dir=subjects_dir)\n",
    "\n",
    "brain_data.add_data(hemi_data, hemi=hemi, fmin=fmin, \n",
    "                    fmid=fmid, fmax=fmax, colormap='hot',\n",
    "                    initial_time=hemi_initial_time,\n",
    "                    time=hemi_times, vertices=hemi_vertices,\n",
    "                    colorbar=False, time_label=hemi_time_label)\n",
    "\n",
    "time_viewer = TimeViewer(brain_data)\n",
    "time_viewer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can show color bar and time viewer widgets together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b83b2199afe646f2b28acf6562c8bd13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p style=\"color: None\"><b>Sample</b></p>'), HBox(children=(Figure(animation=500.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "brain_data = Brain(subject_id, hemi, surf,\n",
    "                   size=400, subjects_dir=subjects_dir)\n",
    "brain_data.add_data(hemi_data, fmin=fmin, hemi=hemi,\n",
    "                    fmax=fmax, colormap='hot',\n",
    "                    initial_time=hemi_initial_time,\n",
    "                    time=hemi_times, vertices=hemi_vertices,\n",
    "                    colorbar=True, time_label=hemi_time_label)\n",
    "\n",
    "time_viewer = TimeViewer(brain_data)\n",
    "time_viewer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plot MNE Source Estimates Signed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from mne import read_source_estimate\n",
    "\n",
    "from ipysurfer import plot_source_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /home/okozyn/mne_data/MNE-sample-data/MEG/sample/sample_audvis_filt-0-40_raw.fif...\n",
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102)  idle\n",
      "        PCA-v2 (1 x 102)  idle\n",
      "        PCA-v3 (1 x 102)  idle\n",
      "        Average EEG reference (1 x 60)  idle\n",
      "    Range : 6450 ... 48149 =     42.956 ...   320.665 secs\n",
      "Ready.\n",
      "Current compensation grade : 0\n",
      "319 events found\n",
      "Event IDs: [ 1  2  3  4  5 32]\n",
      "72 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "Created an SSP operator (subspace dimension = 3)\n",
      "4 projection items activated\n",
      "Loading data for 72 events and 106 original time points ...\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on MAG : ['MEG 1711']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "17 bad epochs dropped\n",
      "Estimating covariance using SHRUNK\n",
      "Done.\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Using cross-validation to select the best estimator.\n",
      "Number of samples used : 1705\n",
      "[done]\n",
      "Number of samples used : 1705\n",
      "[done]\n",
      "log-likelihood on unseen data (descending order):\n",
      "   shrunk: -1480.993\n",
      "   empirical: -1628.225\n",
      "selecting best estimator: shrunk\n",
      "Reading forward solution from /home/okozyn/mne_data/MNE-sample-data/MEG/sample/sample_audvis-meg-oct-6-fwd.fif...\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    Distance information added...\n",
      "    [done]\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    Distance information added...\n",
      "    [done]\n",
      "    2 source spaces read\n",
      "    Desired named matrix (kind = 3523) not available\n",
      "    Read MEG forward solution (7498 sources, 306 channels, free orientations)\n",
      "    Source spaces transformed to the forward solution coordinate frame\n",
      "    Average patch normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Computing inverse operator with 305 channels.\n",
      "    Created an SSP operator (subspace dimension = 3)\n",
      "estimated rank (mag + grad): 302\n",
      "Setting small MEG eigenvalues to zero.\n",
      "Not doing PCA for MEG.\n",
      "Total rank is 302\n",
      "Creating the depth weighting matrix...\n",
      "    203 planar channels\n",
      "    limit = 7265/7498 = 10.037795\n",
      "    scale = 2.52065e-08 exp = 0.8\n",
      "Computing inverse operator with 305 channels.\n",
      "Creating the source covariance matrix\n",
      "Applying loose dipole orientations. Loose value of 0.2.\n",
      "Whitening the forward solution.\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n",
      "    largest singular value = 4.65276\n",
      "    scaling factor to adjust the trace = 1.03619e+19\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 55\n",
      "    Created the regularized inverter\n",
      "    Created an SSP operator (subspace dimension = 3)\n",
      "    Created the whitener using a full noise covariance matrix (3 small eigenvalues omitted)\n",
      "    Computing noise-normalization factors (dSPM)...\n",
      "[done]\n",
      "Applying inverse operator to \"aud_r\"...\n",
      "    Picked 305 channels from the data\n",
      "    Computing inverse...\n",
      "    Eigenleads need to be weighted ...\n",
      "    dSPM...\n",
      "[done]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mne\n",
    "from mne.datasets import sample\n",
    "from mne.minimum_norm import make_inverse_operator, apply_inverse\n",
    "\n",
    "# Process MEG data\n",
    "\n",
    "data_path = sample.data_path()\n",
    "raw_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw.fif'\n",
    "\n",
    "raw = mne.io.read_raw_fif(raw_fname)  # already has an average reference\n",
    "events = mne.find_events(raw, stim_channel='STI 014')\n",
    "\n",
    "event_id = dict(aud_r=1)  # event trigger and conditions\n",
    "tmin = -0.2  # start of each epoch (200ms before the trigger)\n",
    "tmax = 0.5  # end of each epoch (500ms after the trigger)\n",
    "raw.info['bads'] = ['MEG 2443', 'EEG 053']\n",
    "picks = mne.pick_types(raw.info, meg=True, eeg=False, eog=True,\n",
    "                       exclude='bads')\n",
    "baseline = (None, 0)  # means from the first instant to t = 0\n",
    "reject = dict(grad=4000e-13, mag=4e-12, eog=150e-6)\n",
    "\n",
    "epochs = mne.Epochs(raw, events, event_id, tmin, tmax, proj=True, picks=picks,\n",
    "                    baseline=baseline, reject=reject)\n",
    "\n",
    "###############################################################################\n",
    "# Compute regularized noise covariance\n",
    "# ------------------------------------\n",
    "#\n",
    "# For more details see :ref:`tut_compute_covariance`.\n",
    "\n",
    "noise_cov = mne.compute_covariance(\n",
    "    epochs, tmax=0., method=['shrunk', 'empirical'], verbose=True)\n",
    "\n",
    "###############################################################################\n",
    "# Compute the evoked response\n",
    "# ---------------------------\n",
    "# Let's just use MEG channels for simplicity.\n",
    "\n",
    "evoked = epochs.average().pick_types(meg=True)\n",
    "del epochs  # to save memory\n",
    "\n",
    "###############################################################################\n",
    "# Inverse modeling: MNE/dSPM on evoked and raw data\n",
    "# -------------------------------------------------\n",
    "\n",
    "# Read the forward solution and compute the inverse operator\n",
    "fname_fwd = data_path + '/MEG/sample/sample_audvis-meg-oct-6-fwd.fif'\n",
    "fwd = mne.read_forward_solution(fname_fwd)\n",
    "\n",
    "# make an MEG inverse operator\n",
    "info = evoked.info\n",
    "inverse_operator = make_inverse_operator(info, fwd, noise_cov,\n",
    "                                         loose=0.2, depth=0.8)\n",
    "del fwd\n",
    "\n",
    "# Compute inverse solution\n",
    "# ------------------------\n",
    "\n",
    "method = \"dSPM\"\n",
    "snr = 3.\n",
    "lambda2 = 1. / snr ** 2\n",
    "stc = apply_inverse(evoked, inverse_operator, lambda2,\n",
    "                    method=method, pick_ori='normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a83561eef7b64478a0c416af8988f70b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p style=\"color: black\"><b>Sample</b></p>'), HBox(children=(Figure(animation=500.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# stc is an instance of MNE.SourceEstimates class\n",
    "# that holds signed data \n",
    "fig = plot_source_estimates(stc, subject=subject_id, \n",
    "                            surface='inflated', hemi='both', \n",
    "                            colormap='auto', smoothing_steps=10,\n",
    "                            time_unit='s', time_label='auto',\n",
    "                            transparent=False, alpha=1.0,\n",
    "                            time_viewer=True, clim='auto', size=400,\n",
    "                            subjects_dir=subjects_dir, background=\"black\",\n",
    "                            initial_time=0.09, colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Creating a Screenshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8296ea777c0a435d991eeb33c17ce139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p style=\"color: black\"><b>Sample</b></p>'), HBox(children=(Figure(animation=500.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# stc is an instance of MNE.SourceEstimates class\n",
    "# that holds signed data\n",
    "fig = plot_source_estimates(stc, subject=subject_id, \n",
    "                            surface='inflated', hemi='both', \n",
    "                            colormap='auto', smoothing_steps=10,\n",
    "                            time_unit='s', time_label='auto',\n",
    "                            transparent=False, alpha=1.0,\n",
    "                            time_viewer=True, clim='auto', size=400,\n",
    "                            subjects_dir=subjects_dir, background=\"black\",\n",
    "                            initial_time=0.09, colorbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python (mne_g3d)",
   "language": "python",
   "name": "mne_g3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
